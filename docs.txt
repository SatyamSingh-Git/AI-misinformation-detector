An advanced, multimodal AI tool designed to analyze and verify content credibility. This application goes beyond simple "fake news" scores, providing users with a detailed forensic breakdown of text and images to foster media literacy and combat misinformation.


‚ú® Key Features
Multimodal Analysis: Accepts text, image URLs, or direct image uploads for a comprehensive analysis.
Gemini-Powered Fact-Checking: Leverages Google's Gemini 2.5 Flash model to perform deep factual verification, provide corrections, and enrich content with critical context.
AI Image Forensics: Employs a multi-layered approach to detect AI-generated images by analyzing metadata and using Gemini's advanced visual reasoning to spot subtle artifacts.
Linguistic & Coherence Analysis: Uses specialized models to detect sensationalized language and verify if an article's text semantically matches its imagery.
Explainable & Sourced Results: Presents a detailed breakdown of its findings, including a confidence score, a step-by-step explanation, and links to credible sources to build user trust.
Professional Dashboard UI: Features a responsive, side-by-side layout for an intuitive and efficient user experience on all devices.
Browser Extension: A fully integrated Chrome extension for real-time analysis directly in the user's workflow.


üõ†Ô∏è Tech Stack & Architecture
This project is a full-stack monorepo with three main components: a Python backend, a React web app, and a React-based browser extension.
Component	Technology	Purpose
Backend	FastAPI (Python)	High-performance API for handling requests and orchestrating AI services.
Web App	React.js (JavaScript)	The main user-facing dashboard for content submission and analysis.
Extension	React.js & Manifest V3	For in-browser, real-time analysis of active web pages.
AI/ML	Google Gemini 1.5 Flash	The core reasoning engine for fact-checking, visual forensics, and enrichment.
Hugging Face Transformers	For specialized tasks like sentiment analysis (detecting emotive language).
OpenAI CLIP	For measuring the semantic similarity between images and text.
Database	SQLAlchemy & SQLite/PostgreSQL	For storing crowdsourced feedback and other potential data.
Container	Docker & Docker Compose	For creating a portable, production-ready development environment.


üåä Flow of Information & Data
The application follows a clear, orchestrated flow from user input to final analysis, designed for robustness and clarity.
code
Mermaid
graph TD
    subgraph User Interface
        A[React Web App]
        B[Chrome Extension]
    end

    subgraph User Input
        C[Text Content]
        D[Image URL]
        E[Image File Upload]
    end

    subgraph FastAPI Backend
        F[API Endpoint /analyze]
        G[AnalysisService Orchestrator]
        H[ForensicsService]
        I[GeminiService]
        J[Sentiment & CLIP Models]
    end

    subgraph External AI Models
        K[Google Gemini API]
        L[Hugging Face Models]
    end

    A -- "Text, URL, or File" --> F
    B -- "Scraped Text & URL" --> F
    C --> A
    D --> A
    E --> A

    F -- "Request Data" --> G
    G -- "Image Bytes" --> H
    G -- "Text/Claim" --> I
    G -- "Text/Image" --> J

    H -- "Visual Reasoning Prompt" --> K
    I -- "Fact-Check & Enrichment Prompt" --> K
    J -- "Linguistic Analysis" --> L

    K -- "Rich JSON Response" --> H & I
    L -- "Sentiment Score" --> J

    H & I & J -- "Synthesized Results" --> G
    G -- "Final Rich Payload (JSON)" --> F
    F -- "200 OK" --> A & B

    A -- "Renders Professional UI" --> User
    B -- "Renders Popup UI" --> User
üß† Core Concepts, Strategies, and Ideas
This tool was built on several core principles to make it more effective and trustworthy than a simple classifier.
Beyond a Single Score: We intentionally moved away from a single "credibility score" early on. A number is meaningless without context. The goal is to provide a verdict with evidence, empowering the user to make their own informed decision.
Multi-Layered Forensic Analysis: We treat misinformation detection like a digital forensics investigation. Instead of relying on one signal, we gather evidence from multiple, independent layers:
Factual Layer (Gemini): Is the core claim true?
Visual Layer (Gemini Vision): Does this image make sense physically and logically?
Metadata Layer (Pillow): Does the image have the digital "fingerprints" of a real camera?
Linguistic Layer (Transformers): Is the language designed to manipulate emotions?
Coherence Layer (CLIP): Is the image being used in the correct context?
LLM as a Reasoning Engine, Not Just a Knowledge Base: Our "super-prompt" for Gemini is the heart of the engine. We don't just ask it "is this true?". We instruct it to act as a Trust & Safety analyst, forcing it to provide a verdict, reasoning, corrections, and sources in a structured format. This makes the output reliable and easy to parse.
Graceful Degradation: The system is designed to be robust. If a particular analysis fails (e.g., an image URL is broken), it can still provide results from the other successful analyses, rather than crashing entirely.
ü§ñ AI Models Used
Model	Source	Role(s)
Gemini 1.5 Flash	Google AI	1. Fact-Checking & Correction: Verifies claims against its vast knowledge base. <br> 2. Contextual Enrichment: Provides additional relevant information. <br> 3. Image-to-Text: Describes images to create a claim for image-only analysis. <br> 4. Visual Forensic Reasoning: Acts as an expert eye to spot signs of AI generation.
distilbert-base...	Hugging Face	Sentiment Analysis: A lightweight but effective model used to detect strong negative sentiment, a common indicator of emotionally manipulative or biased language.
openai/clip-vit...	Hugging Face	Image-Text Coherence: Measures the semantic similarity between an image and a piece of text to detect if an image is being used out of context.
üöÄ Getting Started: Setup and Installation
Follow these steps to get the entire project running on your local machine.
Prerequisites
Python 3.8+
Node.js v16+ and npm
Docker and Docker Compose (Recommended for database)
A Google Gemini API Key from Google AI Studio.
1. Clone the Repository
code
Bash
git clone <your-repository-url>
cd misinformation-detector
2. Backend Setup
code
Bash
# Navigate to the backend directory
cd backend

# Create and activate a Python virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install all Python dependencies
pip install -r requirements.txt

# Create a .env file for your API key
# Create a new file named .env in the `backend/` directory and add your key:
echo "GOOGLE_API_KEY='YOUR_GEMINI_API_KEY_HERE'" > .env
3. Frontend Setup
code
Bash
# Navigate to the frontend directory from the root
cd frontend

# Install all Node.js dependencies
npm install

# The frontend uses a .env file to know the backend's address.
# This is already configured correctly in the provided files.
4. Running the Application
You will need three separate terminals running simultaneously.
Terminal 1: Start the Backend
code
Bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload
# The API will be running at http://127.0.0.1:8000
Terminal 2: Start the Frontend Web App
code
Bash
cd frontend
npm start
# The web app will open at http://localhost:3000
Terminal 3: Build the Chrome Extension
The extension is not "run" but "built".
code
Bash
cd extension
npm install # If you haven't already
npm run build
# This will create a `build` folder inside `extension/`
5. Loading the Chrome Extension
Open Google Chrome and navigate to chrome://extensions.
Enable "Developer mode" in the top-right corner.
Click "Load unpacked".
Select the misinformation-detector/extension/build folder.
The extension will appear, and you can pin it to your toolbar.
üó∫Ô∏è Future Roadmap
Video & Audio Analysis: Integrate models to detect deepfake videos and cloned voices.
Source Credibility Database: Build a historical database to track the reliability of news domains over time.
Browser-Side AI: Utilize WebML to run lighter models (like sentiment analysis) directly in the browser for enhanced privacy and speed.
Integration with Perplexity API: Add Perplexity as an alternative or supplementary reasoning engine for sourced answers.
üìÑ License
This project is licensed under the MIT License. See the LICENSE file for details.
üôè Acknowledgements
The teams at Google for the powerful Gemini models.
Hugging Face for democratizing access to state-of-the-art NLP models.
The open-source community for the incredible tools that made this project possible.
